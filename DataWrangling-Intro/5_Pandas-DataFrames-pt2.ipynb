{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling Part 5 - Pandas Part 2\n",
    "\n",
    "The following report was submitted as part of my Master of Data Science coursework on Data Wrangling. This report is the final in a five part series where I showcase work on various topics relating to Data Wrangling. This report is the second of two reports on the popular library Pandas. \n",
    "\n",
    "The main scope of this report was to demonstrate how Pandas can emulate SQL queries and provide similar outputs. An exploration of the performance of Pandas and SQL was done to provide insight into whether an SQL database or a pandas is a better option for your data analysis project."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with *pandas* Data Frames (Part 2)\n",
    "\n",
    "&emsp; **Author:** Daniel Gladman <br>\n",
    "&emsp; **Originally Written:** 2023-04-13 <br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This report will use each of datasets belonging to the well-known NYCFlights13 package, which includes datasets consisting of flights, weather, planes, airlines and airports. The data was downloaded and saved prior to beginning the tasks in this report. The purpose of this report is to compare data querying methods, syntaxes and performance between native pandas and SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries\n",
    "\n",
    "First the libraries used in this task shall be imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQLite is a software library that is included within base python and provides a serverless relational database management system (RDBMS). SQLite is able to store and manage data in a single .db file.\n",
    "\n",
    "Pandas is a powerful external library that is built ontop of Numpy and is used primarily for data manipulation, analysis, and cleaning. OS is an inbuilt python library that facilitates interaction with the operating system via python.\n",
    "\n",
    "Before any experiment, it is ideal to declare a prediction (or hypothesis) before performing any analysis, and even more ideally it is better for the hypothesis to be grounded in some theory. Given that in order to return an output using SQL queries, the data must be extracted from the database and maniuplated into a pandas DataFrame, it is expected that the native pandas queries will be quicker than the SQL queries. When querying directly on a pandas dataframe using pandas, the lack of extraction should naturally make the process faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data.\n",
    "\n",
    "First, the datasets will be loaded directly into pandas and then into SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['airlines', 'airports', 'flights', 'planes', 'weather']\n",
    "db_path = './data/nycflights13.db'\n",
    "\n",
    "airlines, airports, flights, planes, weather = [pd.read_csv(f\"./data/nycflights13_{dataset}.csv.gz\", comment=\"#\") for dataset in datasets]\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "if not os.path.exists(db_path):\n",
    "    airlines.to_sql(\"airlines\", conn)\n",
    "    airports.to_sql(\"airports\", conn)\n",
    "    flights.to_sql(\"flights\", conn)\n",
    "    planes.to_sql(\"planes\", conn)\n",
    "    weather.to_sql(\"weather\", conn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: \"SELECT DISTINCT\" on Single Column\n",
    "\n",
    "The first SQL query returns the unique values within a specific column. In this case, it will be the unique values within the engine column in the planes database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Turbo-fan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Turbo-jet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reciprocating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 Cycle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Turbo-shaft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Turbo-prop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          engine\n",
       "0      Turbo-fan\n",
       "1      Turbo-jet\n",
       "2  Reciprocating\n",
       "3        4 Cycle\n",
       "4    Turbo-shaft\n",
       "5     Turbo-prop"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task1_sql=pd.read_sql_query(\"\"\"SELECT DISTINCT engine FROM planes\"\"\", conn)\n",
    "task1_sql"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **PANDAS Equivalent of \"SELECT DISTINCT\"**\n",
    "\n",
    "Two proposed solutions shall be executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed: Outputs are Equal\n"
     ]
    }
   ],
   "source": [
    "task1_my = pd.DataFrame(planes['engine'].unique(), columns=['engine'])\n",
    "try:\n",
    "    pd.testing.assert_frame_equal(task1_sql, task1_my)\n",
    "    print(\"Test passed: Outputs are Equal\")\n",
    "except AssertionError as e:\n",
    "    print(\"Test failed:\", e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first solution involves creating a new dataframe using the output of the pandas.unique() method. The pandas.unique() method uses a hash table to return the unique values in a series. Uniques are returned in order of appearance according to the documentation. \n",
    "\n",
    "When this method is called on a the planes\\['engine'\\], it produces the desired information. However, to ensure that the format matches the output of the SQL query, the unique values need to be assigned to a new DataFrame.\n",
    "\n",
    "There is another method to achieve the same result but without creating a new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed: Outputs are Equal\n"
     ]
    }
   ],
   "source": [
    "task1_my2 = planes[['engine']].drop_duplicates().reset_index(drop=True)\n",
    "try:\n",
    "    pd.testing.assert_frame_equal(task1_sql, task1_my2)\n",
    "    print(\"Test passed: Outputs are Equal\")\n",
    "except AssertionError as e:\n",
    "    print(\"Test failed:\", e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, the pandas.drop_duplicates() method is called on the pandas series to produce the same output. Dropping duplicate entries will result in only the unique entires remaining in the series. The difference in this case is that drop_duplicates() can be applied directly to a DataFrame object, whereas the pandas.unique() method can only be used on a series which must be converted back into a DataFrame to match the SQL output."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 1 - Performance test**\n",
    "\n",
    "The results of the performance test are below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "651 µs ± 4.77 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "pd.read_sql_query(\"\"\"SELECT DISTINCT engine FROM planes\"\"\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177 µs ± 1.65 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "pd.DataFrame(planes['engine'].unique(), columns=['engine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482 µs ± 6.8 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "planes[['engine']].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the native pandas methods performed better than the SQL query, with the unique() method performing considerably better than the drop_duplicates method. Where possible, it is better to use the pandas.unique() method in these situations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: \"SELECT DISTINCT\" on multiple columns.\n",
    "\n",
    "The next SQL query returns the unique values within two specific columns. In this case, it will be the unique values within the engine and type columns in the planes database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>engine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fixed wing multi engine</td>\n",
       "      <td>Turbo-fan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fixed wing multi engine</td>\n",
       "      <td>Turbo-jet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fixed wing single engine</td>\n",
       "      <td>Reciprocating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fixed wing multi engine</td>\n",
       "      <td>Reciprocating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fixed wing single engine</td>\n",
       "      <td>4 Cycle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rotorcraft</td>\n",
       "      <td>Turbo-shaft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fixed wing multi engine</td>\n",
       "      <td>Turbo-prop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       type         engine\n",
       "0   Fixed wing multi engine      Turbo-fan\n",
       "1   Fixed wing multi engine      Turbo-jet\n",
       "2  Fixed wing single engine  Reciprocating\n",
       "3   Fixed wing multi engine  Reciprocating\n",
       "4  Fixed wing single engine        4 Cycle\n",
       "5                Rotorcraft    Turbo-shaft\n",
       "6   Fixed wing multi engine     Turbo-prop"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task2_sql=pd.read_sql_query(\"\"\"SELECT DISTINCT type, engine FROM planes\"\"\", conn)\n",
    "task2_sql"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PANDAS Equivalent of \"SELECT DISTINCT\" on multiple columns.**\n",
    "\n",
    "In this case, it is not possible to utilize the pandas.unique() method as that method only works on a single series of data, whereas in this case the unique values must be unique combinations of two columns.\n",
    "\n",
    "Fortunately, the drop_duplicaties method is capable of handling this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed: Outputs are Equal\n"
     ]
    }
   ],
   "source": [
    "task2_my = planes[['type', 'engine']].drop_duplicates().reset_index(drop=True)\n",
    "try:\n",
    "    pd.testing.assert_frame_equal(task2_sql, task2_my)\n",
    "    print(\"Test passed: Outputs are Equal\")\n",
    "except AssertionError as e:\n",
    "    print(\"Test failed:\", e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As earlier the drop_duplicates method can be applied to multiple columns at once, producing the same output as the SQL query."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 2 - Performance test**\n",
    "\n",
    "The results of the performance test are below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 µs ± 8.33 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "pd.read_sql_query(\"\"\"SELECT DISTINCT type, engine FROM planes\"\"\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "877 µs ± 8.98 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "planes[['type', 'engine']].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, this time the drop_duplciates method was only marginally better than the SQL query. It seems that perhaps as the queries become more complicated, SQL may begin to outperform pandas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: \"SELECT COUNT / GROUP BY\" on single column."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This SQL query  reads the \"planes\" table and counts the number of rows by the type of engine. It then sorts the results by engine in alphabetical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT(*)</th>\n",
       "      <th>engine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>4 Cycle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>Reciprocating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2750</td>\n",
       "      <td>Turbo-fan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>535</td>\n",
       "      <td>Turbo-jet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Turbo-prop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Turbo-shaft</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   COUNT(*)         engine\n",
       "0         2        4 Cycle\n",
       "1        28  Reciprocating\n",
       "2      2750      Turbo-fan\n",
       "3       535      Turbo-jet\n",
       "4         2     Turbo-prop\n",
       "5         5    Turbo-shaft"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task3_sql=pd.read_sql_query(\"\"\"SELECT COUNT(*), engine FROM planes GROUP BY engine\"\"\", conn)\n",
    "task3_sql"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PANDAS Equivalent of  \"SELECT COUNT / GROUP BY\" on single column.**\n",
    "\n",
    "To replicate the SQL output (out of order indices as well), it is possible to do this in a roundabout way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed: Outputs are Equal\n"
     ]
    }
   ],
   "source": [
    "engines = planes.groupby(planes['engine'])[['engine']].value_counts().index\n",
    "engine_counts = planes.groupby(planes['engine'])[['engine']].value_counts().values\n",
    "task3_my = pd.DataFrame([engine_counts.T, engines]).T\n",
    "task3_my.columns = ['COUNT(*)', 'engine']\n",
    "task3_my['COUNT(*)'] = task3_my['COUNT(*)'].astype(\"int64\")\n",
    "\n",
    "\n",
    "try:\n",
    "    pd.testing.assert_frame_equal(task3_sql, task3_my)\n",
    "    print(\"Test passed: Outputs are Equal\")\n",
    "except AssertionError as e:\n",
    "    print(\"Test failed:\", e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the code is grouping the data in the \"planes\" DataFrame by the type of engine, and then counting the number of occurrences of each engine type. The indices and counts are assigned to respective variables using the pandas.value_counts() method along with the index or values, which are then assigned into a new pandas DataFrame. However, for this DataFrame assignment to match the SQL output, a series of matrix transposes need to be called. First the output of the engine_counts needs to be transposed such that the DataFrame can be created. Then the DataFrame itself is transposed so the counts and indices are presented as columns. The columns are then renamed to match the SQL output. Finally, the counts are converted to int64, which is a quirk that arises from the value_counts() assignment. If this is not performed, the assert test will fail.\n",
    "\n",
    "However, this is a very convoluted way to replicate the SQL output and is prone to errors (particularly with the dtype re-assignment). So, a different method is proposed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed: Outputs are Equal\n"
     ]
    }
   ],
   "source": [
    "task3_sql.sort_values(by=\"COUNT(*)\", ascending=False, inplace=True)\n",
    "task3_sql.reset_index(drop=True, inplace=True)\n",
    "task3_sql\n",
    "\n",
    "task3_my2 = planes['engine'].value_counts().reset_index()\n",
    "task3_my2.columns = ['engine', 'COUNT(*)']\n",
    "task3_my2 = task3_my2[['COUNT(*)', 'engine']]\n",
    "\n",
    "try:\n",
    "    pd.testing.assert_frame_equal(task3_sql, task3_my2)\n",
    "    print(\"Test passed: Outputs are Equal\")\n",
    "except AssertionError as e:\n",
    "    print(\"Test failed:\", e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this solution to work and pass the assert test, the SQL output must be reordered by the descending order of the counts instead of the engine. This is achieved by calling the pandas.sort_values() method. However, calling this will cuse the indices to fall out of sequential order, which will break the assert test. So the indices must also be reset.\n",
    "\n",
    "This pandas code performs exactly the same operations using value_counts(), but it does so without the need to explicitly call the group_by method or create a new DataFrame; it performs grouping by perfoming value_counts on just the engine column. By calling reset_index(), the output will revert back to a DataFrame object instead of a summary table. However, for this DataFrame to pass the assert test, the columns need to be renamed to match the SQL output column names and also the order of the columns must be switched."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 3 - Performance test**\n",
    "\n",
    "The results of the performance test are below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3 ms ± 16.5 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "pd.read_sql_query(\"\"\"SELECT COUNT(*), engine FROM planes GROUP BY engine\"\"\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.68 ms ± 28.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "engines = planes.groupby(planes['engine'])[['engine']].value_counts().index\n",
    "engine_counts = planes.groupby(planes['engine'])[['engine']].value_counts().values\n",
    "task3_my = pd.DataFrame([engine_counts.T, engines]).T\n",
    "task3_my.columns = ['COUNT(*)', 'engine']\n",
    "task3_my['COUNT(*)'] = task3_my['COUNT(*)'].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.36 ms ± 17.2 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "task3_my2 = planes['engine'].value_counts().reset_index()\n",
    "task3_my2.columns = ['engine', 'COUNT(*)']\n",
    "task3_my2 = task3_my2.astype({'COUNT(*)': 'int64'})\n",
    "task3_my2 = task3_my2.loc[:, ['COUNT(*)', 'engine']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly the inefficient method performed the slowest, particularly as it required multiple transposing of the data to wrangle the data into the correct format. However surprisingly, the SQL query was marginally faster than the more efficient pandas solution. However, it is likely that the additional steps required to massage the data to match the SQL output format are adding additional time. So it is possible that the pandas method is still faster, however the difference is likely to the negligible. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: \"SELECT COUNT / GROUP BY\" on multiple columns.\n",
    "\n",
    "The next SQL query is similar to the previous, but this time it is performed on multiple columns. Specifically, this code reads the \"planes\" table and counts the number of rows grouped by engine and type. It returns a DataFrame that is sorted alphabetically by engine and then type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT(*)</th>\n",
       "      <th>engine</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>4 Cycle</td>\n",
       "      <td>Fixed wing single engine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Reciprocating</td>\n",
       "      <td>Fixed wing multi engine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>Reciprocating</td>\n",
       "      <td>Fixed wing single engine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2750</td>\n",
       "      <td>Turbo-fan</td>\n",
       "      <td>Fixed wing multi engine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>535</td>\n",
       "      <td>Turbo-jet</td>\n",
       "      <td>Fixed wing multi engine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>Turbo-prop</td>\n",
       "      <td>Fixed wing multi engine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>Turbo-shaft</td>\n",
       "      <td>Rotorcraft</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   COUNT(*)         engine                      type\n",
       "0         2        4 Cycle  Fixed wing single engine\n",
       "1         5  Reciprocating   Fixed wing multi engine\n",
       "2        23  Reciprocating  Fixed wing single engine\n",
       "3      2750      Turbo-fan   Fixed wing multi engine\n",
       "4       535      Turbo-jet   Fixed wing multi engine\n",
       "5         2     Turbo-prop   Fixed wing multi engine\n",
       "6         5    Turbo-shaft                Rotorcraft"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task4_sql=pd.read_sql_query(\"\"\"SELECT COUNT(*), engine, type FROM planes\n",
    "                               GROUP BY engine, type\"\"\", conn)\n",
    "task4_sql"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PANDAS Equivalent of \"SELECT COUNT / GROUP BY\" on multiple columns.**\n",
    "\n",
    "Similarly to the single column, this solution can be achieved in two ways. This time however, I will not manually assign the indices and values to seperate variables. This is actually not neccessary, and simply using the groupby() method along with reset_index() method will create the desired DataFrame object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed: Outputs are Equal\n"
     ]
    }
   ],
   "source": [
    "task4_my = planes.groupby(['engine', 'type'])[['engine', 'type']].value_counts().reset_index()\n",
    "task4_my.columns = ['engine', 'type', 'COUNT(*)']\n",
    "task4_my = task4_my[['COUNT(*)','engine', 'type']]\n",
    "try:\n",
    "    pd.testing.assert_frame_equal(task4_sql, task4_my)\n",
    "    print(\"Test passed: Outputs are Equal\")\n",
    "except AssertionError as e:\n",
    "    print(\"Test failed:\", e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here the code works just as it did earlier, but this time there are two columns instead of one. Also, the column names and orders need to be adjusted to match the SQL output and pass the assert test. This code is much simpler and cleaner than the previous version of it in the previous task and should perform better on testing.\n",
    "\n",
    "The second solution is identical to the Task 3 solution, but this time the DataFrame is filtered by two columns instead of one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed: Outputs are Equal\n"
     ]
    }
   ],
   "source": [
    "task4_sql.sort_values(by=\"COUNT(*)\", ascending=False, inplace=True)\n",
    "task4_sql.reset_index(drop=True, inplace=True)\n",
    "\n",
    "task4_my2 = planes[['engine', 'type']].value_counts().reset_index()\n",
    "task4_my2.columns = ['engine', 'type','COUNT(*)']\n",
    "task4_my2 = task4_my2[['COUNT(*)', 'engine', 'type']]\n",
    "try:\n",
    "    pd.testing.assert_frame_equal(task4_sql, task4_my2)\n",
    "    print(\"Test passed: Outputs are Equal\")\n",
    "except AssertionError as e:\n",
    "    print(\"Test failed:\", e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, the row ordering needs to be adjusted on the SQL output to pass the assertion test. This solution will automatically sort the rows by the Count column in a descending order."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 4 - Performance test**\n",
    "\n",
    "The results of the performance test are below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.93 ms ± 16.9 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "pd.read_sql_query(\"\"\"SELECT COUNT(*), engine, type FROM planes\n",
    "                    GROUP BY engine, type\"\"\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.59 ms ± 37.4 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "task4_my = planes.groupby(['engine', 'type'])[['engine', 'type']].value_counts().reset_index()\n",
    "task4_my.columns = ['engine', 'type', 'COUNT(*)']\n",
    "task4_my = task4_my[['COUNT(*)','engine', 'type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.09 ms ± 93.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "task4_my2 = planes[['engine', 'type']].value_counts().reset_index()\n",
    "task4_my2.columns = ['engine', 'type','COUNT(*)']\n",
    "task4_my2 = task4_my2[['COUNT(*)', 'engine', 'type']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, it appears the that groupby method is considerably slower than applying value_counts directly on the subsection of the DataFrame. However, the SQL query was the fastest performer on this problem. It may still be that the additional steps to match the SQL output are slowing down the test on the pandas solutions, however the gap is starting to increase so it may be that the SQL query is faster for this type of problem. Again, it appears that as the problems become more complicated, SQL will start to perform better."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: \"SELECT MIN, MEAN, MAX OF  multiple GROUPED columns.\n",
    "\n",
    "The next SQL query reads the \"planes\" table and performs minimum, maximum, and mean aggregations of the year based on the combined engine type and manufacturer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MIN(year)</th>\n",
       "      <th>AVG(year)</th>\n",
       "      <th>MAX(year)</th>\n",
       "      <th>engine</th>\n",
       "      <th>manufacturer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1975.0</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>4 Cycle</td>\n",
       "      <td>CESSNA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4 Cycle</td>\n",
       "      <td>JOHN G HESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reciprocating</td>\n",
       "      <td>AMERICAN AIRCRAFT INC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>Reciprocating</td>\n",
       "      <td>AVIAT AIRCRAFT INC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reciprocating</td>\n",
       "      <td>BARKER JACK L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MIN(year)  AVG(year)  MAX(year)         engine           manufacturer\n",
       "0     1975.0     1975.0     1975.0        4 Cycle                 CESSNA\n",
       "1        NaN        NaN        NaN        4 Cycle            JOHN G HESS\n",
       "2        NaN        NaN        NaN  Reciprocating  AMERICAN AIRCRAFT INC\n",
       "3     2007.0     2007.0     2007.0  Reciprocating     AVIAT AIRCRAFT INC\n",
       "4        NaN        NaN        NaN  Reciprocating          BARKER JACK L"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task5_sql=pd.read_sql_query(\"\"\"SELECT MIN(year), AVG(year), MAX(year), engine, manufacturer\n",
    "                               FROM planes \n",
    "                               GROUP BY engine, manufacturer\"\"\", conn)\n",
    "task5_sql.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PANDAS Equivalent of \"SELECT MIN, MEAN, MAX OF  multiple GROUPED columns.**\n",
    "\n",
    "Once again, I will provide two solutions; an inefficient one and a more efficient one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed: Outputs are Equal\n"
     ]
    }
   ],
   "source": [
    "plane_mins = planes.groupby(['engine', 'manufacturer'])['year'].min().reset_index()\n",
    "plane_means = planes.groupby(['engine', 'manufacturer'])['year'].mean().reset_index()\n",
    "plane_maxs = planes.groupby(['engine', 'manufacturer'])['year'].max().reset_index()\n",
    "\n",
    "result = pd.merge(plane_mins, plane_means, how='left', on=['engine', 'manufacturer'])\n",
    "result = pd.merge(result, plane_maxs, how='left', on=['engine', 'manufacturer'])\n",
    "\n",
    "result.rename(columns={'year_x': 'MIN(year)', \n",
    "                       'year_y': 'AVG(year)',\n",
    "                       'year': 'MAX(year)'}, inplace=True)\n",
    "\n",
    "task5_my = result[['MIN(year)','AVG(year)','MAX(year)','engine','manufacturer']]\n",
    "\n",
    "try:\n",
    "    pd.testing.assert_frame_equal(task5_sql, task5_my)\n",
    "    print(\"Test passed: Outputs are Equal\")\n",
    "except AssertionError as e:\n",
    "    print(\"Test failed:\", e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above solution individually performs the min, max and mean aggregations on the year column after grouping by the engine and manufacturer and saves these DataFrames as their own variables. Then to produce the final output, these three DataFrames are merged one by one into a single DataFrame (note: the pd.merge() method can only merge two DataFrames at a time). Then the columns are renamed and reorganized to match the SQL output and pass the assertion test.\n",
    "\n",
    "While this works, there is a better way to solve the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed: Outputs are Equal\n"
     ]
    }
   ],
   "source": [
    "results = planes.groupby(['engine', 'manufacturer']).agg({'year': ['min', 'mean', 'max']}).reset_index()\n",
    "results.columns = ['engine', 'manufacturer', 'MIN(year)', 'AVG(year)', 'MAX(year)']\n",
    "task5_my2 = results[['MIN(year)','AVG(year)','MAX(year)','engine','manufacturer']]\n",
    "\n",
    "try:\n",
    "    pd.testing.assert_frame_equal(task5_sql, task5_my2)\n",
    "    print(\"Test passed: Outputs are Equal\")\n",
    "except AssertionError as e:\n",
    "    print(\"Test failed:\", e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of combining the aggregated dataframes can be simplified by applying the agg() method to the output of the groupby method. The agg() method is a useful method as it can be passed a string, list or dictionary that specifies the desired column or aggregation function. In the above case, the dictionary specifies the column as the key and a list of desired aggregation functions as the value. This approach is ideal if different aggregation functions are to be applied to different columns. The same outcome above can can achieved by passing just the list of the aggregation functions to the agg() method, provided the column is specified as a filter. \n",
    "\n",
    "For example this code would also work:\n",
    "```\n",
    "planes.groupby(['engine', 'manufacturer'])['year'].agg(['min', 'mean', 'max']).reset_index()\n",
    "```\n",
    "\n",
    "Once this is done, as before, the columns are renamed and reorganized such that they match the SQL output."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 5 - Performance test**\n",
    "\n",
    "The results of the performance test are below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1 ms ± 50.8 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "task5_my = pd.read_sql_query(\"\"\"SELECT MIN(year), AVG(year), MAX(year), engine, manufacturer\n",
    "                               FROM planes \n",
    "                               GROUP BY engine, manufacturer\"\"\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.29 ms ± 94.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "plane_mins = planes.groupby(['engine', 'manufacturer'])['year'].min().reset_index()\n",
    "plane_means = planes.groupby(['engine', 'manufacturer'])['year'].mean().reset_index()\n",
    "plane_maxs = planes.groupby(['engine', 'manufacturer'])['year'].max().reset_index()\n",
    "\n",
    "result = pd.merge(plane_mins, plane_means, how='left', on=['engine', 'manufacturer'])\n",
    "result = pd.merge(result, plane_maxs, how='left', on=['engine', 'manufacturer'])\n",
    "\n",
    "result.rename(columns={'year_x': 'MIN(year)', \n",
    "                       'year_y': 'AVG(year)',\n",
    "                       'year': 'MAX(year)'}, inplace=True)\n",
    "\n",
    "task5_my = result[['MIN(year)','AVG(year)','MAX(year)','engine','manufacturer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.47 ms ± 36.2 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "results = planes.groupby(['engine', 'manufacturer']).agg({'year': ['min', 'mean', 'max']}).reset_index()\n",
    "results.columns = ['engine', 'manufacturer', 'MIN(year)', 'AVG(year)', 'MAX(year)']\n",
    "task5_my2 = results[['MIN(year)','AVG(year)','MAX(year)','engine','manufacturer']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inefficient pandas group by methods were unsurprisingly the slowest performer on testing. However, this time the combination of groupby and agg performed signficantly better than the SQL queries. It appears that perhaps pandas may be better for performing aggregation functions than SQL."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: \"FILTER OUT NULL VALUES\" on single columns\n",
    "\n",
    "The next SQL query reads the planes table and simply filters out all the rows in the speed column that are empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tailnum</th>\n",
       "      <th>year</th>\n",
       "      <th>type</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>model</th>\n",
       "      <th>engines</th>\n",
       "      <th>seats</th>\n",
       "      <th>speed</th>\n",
       "      <th>engine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>424</td>\n",
       "      <td>N201AA</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>Fixed wing single engine</td>\n",
       "      <td>CESSNA</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Reciprocating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>427</td>\n",
       "      <td>N202AA</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>Fixed wing multi engine</td>\n",
       "      <td>CESSNA</td>\n",
       "      <td>421C</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Reciprocating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>821</td>\n",
       "      <td>N350AA</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>Fixed wing multi engine</td>\n",
       "      <td>PIPER</td>\n",
       "      <td>PA-31-350</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>162.0</td>\n",
       "      <td>Reciprocating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>893</td>\n",
       "      <td>N364AA</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>Fixed wing multi engine</td>\n",
       "      <td>CESSNA</td>\n",
       "      <td>310Q</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>167.0</td>\n",
       "      <td>Reciprocating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1027</td>\n",
       "      <td>N378AA</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>Fixed wing single engine</td>\n",
       "      <td>CESSNA</td>\n",
       "      <td>172E</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>105.0</td>\n",
       "      <td>Reciprocating</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index tailnum    year                      type manufacturer      model  \\\n",
       "0    424  N201AA  1959.0  Fixed wing single engine       CESSNA        150   \n",
       "1    427  N202AA  1980.0   Fixed wing multi engine       CESSNA       421C   \n",
       "2    821  N350AA  1980.0   Fixed wing multi engine        PIPER  PA-31-350   \n",
       "3    893  N364AA  1973.0   Fixed wing multi engine       CESSNA       310Q   \n",
       "4   1027  N378AA  1963.0  Fixed wing single engine       CESSNA       172E   \n",
       "\n",
       "   engines  seats  speed         engine  \n",
       "0        1      2   90.0  Reciprocating  \n",
       "1        2      8   90.0  Reciprocating  \n",
       "2        2      8  162.0  Reciprocating  \n",
       "3        2      6  167.0  Reciprocating  \n",
       "4        1      4  105.0  Reciprocating  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task6_sql=pd.read_sql_query(\"\"\"SELECT * FROM planes WHERE speed IS NOT NULL\"\"\", conn)\n",
    "task6_sql.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PANDAS Equivalent of \"FILTER OUT NULL VALUES\" on single columns**\n",
    "\n",
    "This can easily be replicated using Pandas by putting a filter on the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed: Outputs are Equal\n"
     ]
    }
   ],
   "source": [
    "task6_my = planes[planes['speed'].notna()].reset_index()\n",
    "\n",
    "try:\n",
    "    pd.testing.assert_frame_equal(task6_sql, task6_my)\n",
    "    print(\"Test passed: Outputs are Equal\")\n",
    "except AssertionError as e:\n",
    "    print(\"Test failed:\", e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notna() method can be applied to the speed column to return a series of boolean values. This series can then be applied to the DataFrame to return only the rows within the speed column that contain values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 6 - Performance test**\n",
    "\n",
    "The results of the performance test are below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "944 µs ± 15.8 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "task6_sql=pd.read_sql_query(\"\"\"SELECT * FROM planes WHERE speed IS NOT NULL\"\"\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282 µs ± 4.07 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "task6_my = planes[planes['speed'].notna()].reset_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THe results of the test show that the notna() method is atleast three times faster than the SQL query. Also, it is interesting to note that there was no additional wrangling required to match the SQL output format, so it suggests that the pandas methods may be even faster if they are not required to produce outputs in a specific format."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: \"SELECT\" single column while \"FILTERING\" by multiple conditions\n",
    "\n",
    "The next SQL query reads in the planes table, filters the rows by the column seat where the rows are between 150 and 210 and then returns only the tailnum column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tailnum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N150UW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N151UW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N152UW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N153UW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N154UW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tailnum\n",
       "0  N150UW\n",
       "1  N151UW\n",
       "2  N152UW\n",
       "3  N153UW\n",
       "4  N154UW"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task7_sql=pd.read_sql_query(\"\"\"SELECT tailnum FROM planes \n",
    "                               WHERE seats BETWEEN 150 AND 210 AND year >= 2011\"\"\", conn)\n",
    "task7_sql.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PANDAS Equivalent of \"SELECT\" single column while \"FILTERING\" by multiple conditions**\n",
    "\n",
    "This can be achieved by chaining together the required seat column conditions and applying that as a filter to the DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed: Outputs are Equal\n"
     ]
    }
   ],
   "source": [
    "task7_my = planes[(planes['seats']>=150)&\n",
    "              (planes['seats']<=210)&\n",
    "              (planes['year']>=2011)][['tailnum']].reset_index(drop=True)\n",
    "\n",
    "try:\n",
    "    pd.testing.assert_frame_equal(task7_sql, task7_my)\n",
    "    print(\"Test passed: Outputs are Equal\")\n",
    "except AssertionError as e:\n",
    "    print(\"Test failed:\", e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code filters the entire DataFrame first by all the seat column conditions. Then the 'tailnum' column is selected and the index is reset. This is enough to pass the assertion test. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 7 - Performance test**\n",
    "\n",
    "The results of the performance test are below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601 µs ± 3.18 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "task7_sql=pd.read_sql_query(\"\"\"SELECT tailnum FROM planes \n",
    "                               WHERE seats BETWEEN 150 AND 210 AND year >= 2011\"\"\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624 µs ± 7.18 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "task7_my = planes[(planes['seats']>=150)&\n",
    "              (planes['seats']<=210)&\n",
    "              (planes['year']>=2011)][['tailnum']].reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show that for this task, the SQL query was the faster performer, however the difference between SQL and pandas in this case is negligible."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8: \"SELECT\" multiple columns while \"FILTERING\" on multiple conditions including a column subset.\n",
    "\n",
    "The next SQL query is a little more complicated then the previous task. As before the planes table is read, but this time the \"tailnum\", \"manufacturer\", and \"seats\" columns are selected. Of these columns the rows where the manufacturer is one of \"BOEING\", \"AIRBUS\", or \"EMBRAER\", and the seats are greater than 390 are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tailnum</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>seats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N206UA</td>\n",
       "      <td>BOEING</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N228UA</td>\n",
       "      <td>BOEING</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N272AT</td>\n",
       "      <td>BOEING</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N57016</td>\n",
       "      <td>BOEING</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N670US</td>\n",
       "      <td>BOEING</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tailnum manufacturer  seats\n",
       "0  N206UA       BOEING    400\n",
       "1  N228UA       BOEING    400\n",
       "2  N272AT       BOEING    400\n",
       "3  N57016       BOEING    400\n",
       "4  N670US       BOEING    450"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task8_sql=pd.read_sql_query(\"\"\"SELECT tailnum, manufacturer, seats FROM planes\n",
    "                               WHERE manufacturer IN (\"BOEING\", \"AIRBUS\", \"EMBRAER\") AND seats > 390\"\"\",\n",
    "                                 conn)\n",
    "task8_sql.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PANDAS Equivalent of \"SELECT\" multiple columns while \"FILTERING\" on multiple conditions including a column subset.**\n",
    "\n",
    "Although the task is a little more complicated on the surface, it can be solved using the same pattern as the previous solution while taking advantage of the isin() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed: Outputs are Equal\n"
     ]
    }
   ],
   "source": [
    "task8_my= planes[(planes['manufacturer'].isin([\"BOEING\", \"AIRBUS\", \"EMBRAER\"]))&\n",
    "                 (planes['seats'] > 390)][['tailnum',\n",
    "                                           'manufacturer', \n",
    "                                          'seats']].reset_index(drop=True)\n",
    "\n",
    "try:\n",
    "    pd.testing.assert_frame_equal(task8_sql, task8_my)\n",
    "    print(\"Test passed: Outputs are Equal\")\n",
    "except AssertionError as e:\n",
    "    print(\"Test failed:\", e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Dataframe is filtered by the neccessary conditions, which in this case is seats > 390 and the manufacturer is equal to either Boeing, Airbus or Embraer. The manufacturer condition can be used by passing these terms as a list into the isin() method. Next this output is filtered down to the \"tailnum\", \"manufacturer\", and \"seats\" columns. To pass the assertion test, the indices must be reset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 8 - Performance test**\n",
    "\n",
    "The results of the performance test are below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "895 µs ± 6.99 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "task8_sql=pd.read_sql_query(\"\"\"SELECT tailnum, manufacturer, seats FROM planes\n",
    "                               WHERE manufacturer IN (\"BOEING\", \"AIRBUS\", \"EMBRAER\") AND seats > 390\"\"\",\n",
    "                                 conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "647 µs ± 5.03 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "task8_my= planes[(planes['manufacturer'].isin([\"BOEING\", \"AIRBUS\", \"EMBRAER\"]))&\n",
    "                 (planes['seats'] > 390)][['tailnum',\n",
    "                                           'manufacturer', \n",
    "                                          'seats']].reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show that the SQL query is approximetly ~30 - 40% slower than the pandas methods for this problem."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9: \"SELECT UNIQUE\" values on multiple columsn while \"FILTERING and ORDERING\" by single column: PART 1\n",
    "\n",
    "The next SQL query is the first of two very similar queries that illustrate the importance of selecting the correct column to order by.\n",
    "\n",
    "The query reads the planes table and selects the unique combinations of year and seats where the year column is greater than or equal to 2012. The output is then organised by year in an ascending order and seats in a descending order. In this case, the year is sorted first and then the seats are sorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>seats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012.0</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012.0</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012.0</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012.0</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012.0</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  seats\n",
       "0  2012.0    379\n",
       "1  2012.0    377\n",
       "2  2012.0    260\n",
       "3  2012.0    222\n",
       "4  2012.0    200"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task9_sql=pd.read_sql_query(\"\"\"SELECT DISTINCT year, seats FROM planes\n",
    "                               WHERE year >= 2012 ORDER BY year ASC, seats DESC\"\"\",\n",
    "                                conn)\n",
    "task9_sql.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PANDAS Equivalent of \"SELECT UNIQUE\" values on multiple columsn while \"FILTERING and ORDERING\" by single column: PART 1**\n",
    "\n",
    "This solution will utilize a combination of two methods that have been used when solving some of the prior tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed: Outputs are Equal\n"
     ]
    }
   ],
   "source": [
    "task9_my = planes[planes['year']>=2012][['year',\n",
    "                            'seats']].drop_duplicates().sort_values(by=['year',\n",
    "                                                                        'seats'],\n",
    "                                                                    ascending=[True, \n",
    "                                                                            False]).reset_index(drop=True)\n",
    "\n",
    "try:\n",
    "    pd.testing.assert_frame_equal(task9_sql, task9_my)\n",
    "    print(\"Test passed: Outputs are Equal\")\n",
    "except AssertionError as e:\n",
    "    print(\"Test failed:\", e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code first filters the entire DataFrame by the condition where year is greater than r equl to 2012. Then the seat and year columns are selected and the drop_duplicates() method is applied to extract the unique combinations. Then the sort_values() method is called, however this time, to ensure that multi-column sorting is performed correctly, a list of the columns is passed in as a 'by' parameter. In addition, to ensure the sorting order for both columns is performed correctly, another boolean list is passed into the ascending parameter. \n",
    "\n",
    "Finally to pass the assertion test, the indices are reset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 9 - Performance test**\n",
    "\n",
    "The results of the performance test are below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "594 µs ± 4.28 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "task9_sql=pd.read_sql_query(\"\"\"SELECT DISTINCT year, seats FROM planes\n",
    "                               WHERE year >= 2012 ORDER BY year ASC, seats DESC\"\"\",\n",
    "                                conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.28 ms ± 43.1 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "task9_my = planes[planes['year']>=2012][['year',\n",
    "                            'seats']].drop_duplicates().sort_values(by=['year',\n",
    "                                                                        'seats'],\n",
    "                                                                    ascending=[True, \n",
    "                                                                            False]).reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, this test revealed that the SQL query was faster than the pandas methods by more than double. This is the first result where the disparity was this far in favour of SQL over pandas. Both methods required sorting, so the difference can be purely attributed to the underlying system."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 10: \"SELECT UNIQUE\" values on multiple columns while \"FILTERING and ORDERING\" by single column: PART 2\n",
    "\n",
    "In part 2, the query is essentially the same as part 1, except this time the columns are ordered by seats in descending order and then year in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>seats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012.0</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013.0</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012.0</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013.0</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012.0</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  seats\n",
       "0  2012.0    379\n",
       "1  2013.0    379\n",
       "2  2012.0    377\n",
       "3  2013.0    377\n",
       "4  2012.0    260"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task10_sql=pd.read_sql_query(\"\"\"SELECT DISTINCT year, seats FROM planes\n",
    "                                WHERE year >= 2012 ORDER BY seats DESC, year ASC\"\"\",\n",
    "                                  conn)\n",
    "task10_sql.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PANDAS Equivalent of \"SELECT UNIQUE\" values on multiple columns while \"FILTERING and ORDERING\" by single column: PART 2**\n",
    "\n",
    "The exact same code can be recycled from the previous task with the neccessary amendments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed: Outputs are Equal\n"
     ]
    }
   ],
   "source": [
    "task10_my = planes[planes['year']>=2012][['year',\n",
    "                            'seats']].drop_duplicates().sort_values(by=['seats',\n",
    "                                                                        'year'],\n",
    "                                                                    ascending=[False, \n",
    "                                                                            True]).reset_index(drop=True)\n",
    "\n",
    "try:\n",
    "    pd.testing.assert_frame_equal(task10_sql, task10_my)\n",
    "    print(\"Test passed: Outputs are Equal\")\n",
    "except AssertionError as e:\n",
    "    print(\"Test failed:\", e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only change from part one is the order of the list that is passed into the sort_values() method. This illustrates the importance of understanding the order in which the columns are to be sorted.\n",
    "\n",
    "**NOTE: NO PERFORMANCE TEST WAS PERFORMED AS THIS PROCESS IS INDENTICAL TO THE PREVIOUS TASK**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 11: \"SELECT COUNT / GROUP BY\" on single column while \"FILTERING\" by single condition\n",
    "\n",
    "The next SQL query is an extension of the Count and Group by query from Task 3 but this time a condition is applied first. The planes table is read and a filter is applied where only the rows where the seat column is greater than 200 is selected. Then the grouping and counting is performed on the manufacturer column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>COUNT(*)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AIRBUS</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIRBUS INDUSTRIE</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOEING</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       manufacturer  COUNT(*)\n",
       "0            AIRBUS        66\n",
       "1  AIRBUS INDUSTRIE         4\n",
       "2            BOEING       225"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task11_sql=pd.read_sql_query(\"\"\"SELECT manufacturer, COUNT(*) FROM planes \n",
    "                                WHERE seats > 200 GROUP BY manufacturer\"\"\", conn)\n",
    "task11_sql"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PANDAS Equivalent of \"SELECT COUNT / GROUP BY\" on single column while \"FILTERING\" by single condition**\n",
    "\n",
    "The pattern on how to replicate these queries using pandas only should start to be apparent, as the methods used have already been used to solve previous tasks. The pattern is to filter the DataFrame by the specified condtion, then select the desired columns and perform the desired aggregration or counting function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed: Outputs are Equal\n"
     ]
    }
   ],
   "source": [
    "task11_my = planes[planes['seats'] > 200].groupby(\"manufacturer\")[['manufacturer']].value_counts().reset_index()\n",
    "task11_my.columns = [\"manufacturer\", \"COUNT(*)\"]\n",
    "\n",
    "try:\n",
    "    pd.testing.assert_frame_equal(task11_sql, task11_my)\n",
    "    print(\"Test passed: Outputs are Equal\")\n",
    "except AssertionError as e:\n",
    "    print(\"Test failed:\", e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, to obtain the same sorting method that the SQL output naturally produces, the groupby() method is explicitly stated. This solution is able to produce the result in less lines, but the code is slightly more verbose and difficult to read.\n",
    "\n",
    "On the other hand, the next segment will provide the same output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed: Outputs are Equal\n"
     ]
    }
   ],
   "source": [
    "task11_my2 = planes[planes['seats'] > 200]['manufacturer'].value_counts().reset_index()\n",
    "task11_my2.columns = [\"manufacturer\", \"COUNT(*)\"]\n",
    "task11_my2.sort_values(by='manufacturer', inplace=True)\n",
    "task11_my2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "try:\n",
    "    pd.testing.assert_frame_equal(task11_sql, task11_my2)\n",
    "    print(\"Test passed: Outputs are Equal\")\n",
    "except AssertionError as e:\n",
    "    print(\"Test failed:\", e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code does not use the groupby() method, and instead directly selects the desired column and applies the count after filtering by the seat condition. However, the sorting will be on Count by default. So to pass the assertion test, the rows must be sorted by the manufacturer column."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 11 - Performance test**\n",
    "\n",
    "The results of the performance test are below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "611 µs ± 6.83 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "task11_sql=pd.read_sql_query(\"\"\"SELECT manufacturer, COUNT(*) FROM planes \n",
    "                                WHERE seats > 200 GROUP BY manufacturer\"\"\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.57 ms ± 60.6 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "task11_my = planes[planes['seats'] > 200].groupby(\"manufacturer\")[['manufacturer']].value_counts().reset_index()\n",
    "task11_my.columns = [\"manufacturer\", \"COUNT(*)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768 µs ± 17.3 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "task11_my2 = planes[planes['seats'] > 200]['manufacturer'].value_counts().reset_index()\n",
    "task11_my2.columns = [\"manufacturer\", \"COUNT(*)\"]\n",
    "task11_my2.sort_values(by='manufacturer', inplace=True)\n",
    "task11_my2.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show that the groupby() method was again the slower performer of the pandas solutions. It is becoming apparent that if the task can be performed without using groupby(), then groupby() should be avoided. In this case, the SQL query was the best performer."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 12: \"SELECT COUNT / GROUP BY\" on single column while \"FILTERING\" by single condition based on COUNT\n",
    "\n",
    "This next SQL query provides an interesting spin on the previous task. \n",
    "\n",
    "The planes table is read, then the grouping and counting is performed on the manufacturer column. Then the filter by count is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>COUNT(*)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AIRBUS</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIRBUS INDUSTRIE</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOEING</td>\n",
       "      <td>1630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOMBARDIER INC</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EMBRAER</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MCDONNELL DOUGLAS</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MCDONNELL DOUGLAS AIRCRAFT CO</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MCDONNELL DOUGLAS CORPORATION</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    manufacturer  COUNT(*)\n",
       "0                         AIRBUS       336\n",
       "1               AIRBUS INDUSTRIE       400\n",
       "2                         BOEING      1630\n",
       "3                 BOMBARDIER INC       368\n",
       "4                        EMBRAER       299\n",
       "5              MCDONNELL DOUGLAS       120\n",
       "6  MCDONNELL DOUGLAS AIRCRAFT CO       103\n",
       "7  MCDONNELL DOUGLAS CORPORATION        14"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task12_sql=pd.read_sql_query(\"\"\"SELECT manufacturer, COUNT(*) FROM planes \n",
    "                                GROUP BY manufacturer HAVING COUNT(*) > 10\"\"\", conn)\n",
    "task12_sql"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PANDAS Equivalent of \"SELECT COUNT / GROUP BY\" on single column while \"FILTERING\" by single condition based on COUNT**  \n",
    "\n",
    "This time, the usual pattern that we have become accustomed to cannot be used as the filter must be applied after the grouping and count is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed: Outputs are Equal\n"
     ]
    }
   ],
   "source": [
    "mask = planes['manufacturer'].value_counts() > 10\n",
    "task12_my = planes['manufacturer'].value_counts()[mask].reset_index()\n",
    "task12_my.columns = [\"manufacturer\", \"COUNT(*)\"]\n",
    "task12_my.sort_values(by='manufacturer', inplace=True)\n",
    "task12_my.reset_index(drop=True, inplace=True)\n",
    "\n",
    "try:\n",
    "    pd.testing.assert_frame_equal(task12_sql, task12_my)\n",
    "    print(\"Test passed: Outputs are Equal\")\n",
    "except AssertionError as e:\n",
    "    print(\"Test failed:\", e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve this problem, a masking variable can be created by applying the value_counts to the manufacturer column where the counts are greater than 10. Then this mask can be applied ontop of the same line of code, where reseting the index will create the desired DataFrame.\n",
    "\n",
    "Then to pass the assertion test the columns are renamed and reordered to match the SQL output."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 12 - Performance test**\n",
    "\n",
    "The results of the performance test are below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.56 ms ± 77.4 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "task12_sql=pd.read_sql_query(\"\"\"SELECT manufacturer, COUNT(*) FROM planes \n",
    "                                GROUP BY manufacturer HAVING COUNT(*) > 10\"\"\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13 ms ± 39.1 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "mask = planes['manufacturer'].value_counts() > 10\n",
    "task12_my = planes['manufacturer'].value_counts()[mask].reset_index()\n",
    "task12_my.columns = [\"manufacturer\", \"COUNT(*)\"]\n",
    "task12_my.sort_values(by='manufacturer', inplace=True)\n",
    "task12_my.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the pandas masking method was quicker than the SQL query. It is interesting to note that in the earlier tasks SQL outperformed pandas when filtering by a condition, but the mask approach was not used in those tasks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 13: \"SELECT COUNT / GROUP BY\" on single column while \"FILTERING\" by COUNT and other condition\n",
    "\n",
    "The next SQL query extends upon the previous on by adding an extra condition to the count. The planes table is read and then the grouping and counting is performed on the manufacturer column. Then the filter by countand seats > 200 is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>COUNT(*)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AIRBUS</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOEING</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  manufacturer  COUNT(*)\n",
       "0       AIRBUS        66\n",
       "1       BOEING       225"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task13_sql=pd.read_sql_query(\"\"\"SELECT manufacturer, COUNT(*) FROM planes\n",
    "                                WHERE seats > 200 GROUP BY manufacturer HAVING COUNT(*) > 10\"\"\",\n",
    "                                conn)\n",
    "task13_sql"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PANDAS Equivalent of \"SELECT COUNT / GROUP BY\" on single column while \"FILTERING\" by COUNT and other condition**\n",
    "\n",
    "Once the previous method is understood, it is possible to expand the previous code to solve the problem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed: Outputs are Equal\n"
     ]
    }
   ],
   "source": [
    "mask = planes[planes['seats'] > 200]['manufacturer'].value_counts() > 10\n",
    "task13_my = planes[planes['seats'] > 200]['manufacturer'].value_counts()[mask].reset_index()\n",
    "task13_my.columns = [\"manufacturer\", \"COUNT(*)\"]\n",
    "task13_my.sort_values(by='manufacturer', inplace=True)\n",
    "task13_my.reset_index(drop=True, inplace=True)\n",
    "\n",
    "try:\n",
    "    pd.testing.assert_frame_equal(task13_sql, task13_my)\n",
    "    print(\"Test passed: Outputs are Equal\")\n",
    "except AssertionError as e:\n",
    "    print(\"Test failed:\", e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same masking procedure is followed, but this time the DataFrame is filtered by the other condition (seats > 200) prior to filtering by the value_counts.\n",
    "\n",
    "This boolean filter is then applied to the same line of code. It is important that the syntax matches otherwise the boolean masking will not work properly. \n",
    "\n",
    "As usual, to pass the assertion test, the columns must be renamed and reordered."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 13 - Performance test**\n",
    "\n",
    "The results of the performance test are below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "685 µs ± 21.4 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "task13_sql=pd.read_sql_query(\"\"\"SELECT manufacturer, COUNT(*) FROM planes\n",
    "                                WHERE seats > 200 GROUP BY manufacturer HAVING COUNT(*) > 10\"\"\",\n",
    "                                conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.44 ms ± 31.1 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "mask = planes[planes['seats'] > 200]['manufacturer'].value_counts() > 10\n",
    "task13_my = planes[planes['seats'] > 200]['manufacturer'].value_counts()[mask].reset_index()\n",
    "task13_my.columns = [\"manufacturer\", \"COUNT(*)\"]\n",
    "task13_my.sort_values(by='manufacturer', inplace=True)\n",
    "task13_my.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the SQL query was faster than the pandas method even with masking. The difference however was that the mask itself required additional filtering which has likely slowed pandas down."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 14: \"SELECT COUNT / GROUP BY\" on single column while \"ORDERING\"\n",
    "\n",
    "The next SQL query changes things up slightly by changing the name of the returned column and performing a different sorting order. Also, the results are limited to just 10 rows.\n",
    "\n",
    "The planes table is read and then the grouping and counting is performed on the manufacturer column. The count column is renamed 'howmany' and then the ordering and limiter is specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>howmany</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOEING</td>\n",
       "      <td>1630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIRBUS INDUSTRIE</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOMBARDIER INC</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AIRBUS</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EMBRAER</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MCDONNELL DOUGLAS</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MCDONNELL DOUGLAS AIRCRAFT CO</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MCDONNELL DOUGLAS CORPORATION</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CESSNA</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CANADAIR</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    manufacturer  howmany\n",
       "0                         BOEING     1630\n",
       "1               AIRBUS INDUSTRIE      400\n",
       "2                 BOMBARDIER INC      368\n",
       "3                         AIRBUS      336\n",
       "4                        EMBRAER      299\n",
       "5              MCDONNELL DOUGLAS      120\n",
       "6  MCDONNELL DOUGLAS AIRCRAFT CO      103\n",
       "7  MCDONNELL DOUGLAS CORPORATION       14\n",
       "8                         CESSNA        9\n",
       "9                       CANADAIR        9"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task14_sql=pd.read_sql_query(\"\"\"SELECT manufacturer, COUNT(*) AS howmany\n",
    "                                FROM planes\n",
    "                                GROUP BY manufacturer\n",
    "                                ORDER BY howmany DESC LIMIT 10\"\"\", conn)\n",
    "task14_sql"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PANDAS Equivalent of \"SELECT COUNT / GROUP BY\" on single column while \"ORDERING\"** \n",
    "\n",
    "Up until now, because of the way SQL orders by default, it has been neccessary to call sort_values() to match. This time, the SQL will be ordered in such as way that is congruent with how Pandas orders the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed: Outputs are Equal\n"
     ]
    }
   ],
   "source": [
    "task14_my = planes[['manufacturer']].value_counts().reset_index()[:10]\n",
    "task14_my.columns = [\"manufacturer\", \"howmany\"]\n",
    "try:\n",
    "    pd.testing.assert_frame_equal(task14_sql, task14_my)\n",
    "    print(\"Test passed: Outputs are Equal\")\n",
    "except AssertionError as e:\n",
    "    print(\"Test failed:\", e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code is relatively similar to before, however this time to ensure that the limiter is applied, a split is applied to the DataFrame such that only the first 10 rows are returned."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 14 - Performance test**\n",
    "\n",
    "The results of the performance test are below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.62 ms ± 41.2 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "task14_sql=pd.read_sql_query(\"\"\"SELECT manufacturer, COUNT(*) AS howmany\n",
    "                                FROM planes\n",
    "                                GROUP BY manufacturer\n",
    "                                ORDER BY howmany DESC LIMIT 10\"\"\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.53 ms ± 52.1 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "task14_my = planes[['manufacturer']].value_counts().reset_index()[:10]\n",
    "task14_my.columns = [\"manufacturer\", \"howmany\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show that pandas performed better than SQL on this type of query, however the difference was not big. In an earlier similar task, SQL was slightly faster than pandas and it was hypothesized that pandas would be faster if there was no additional requirement to massage the DataFrame, and this result confirms that hypothesis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 15: \"JOINING\" columns from two dataframes\n",
    "\n",
    "The next SQL query will be the first of a series where multiple tables are joined together.\n",
    "\n",
    "This query reads data from two tables, \"flights\" and \"planes\". Then it selects all columns from the \"flights\" table, as well as the \"year\", \"speed\", and \"seats\" columns from the \"planes\" table while renaming the columns from the \"planes\" table. The resulting DataFrame is created by performing a left join of the two tables on the \"tailnum\" column.\n",
    "\n",
    "A left join is a type of SQL join operation that returns all the rows from the left table (i.e., the table specified first in the join clause) and only the matching rows from the right table. If there are no matching rows in the right table, then the result will contain null values for the columns in the right table. \n",
    "\n",
    "In this case, \"flights\" will be the left table and \"planes\" will be the right table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dep_time</th>\n",
       "      <th>sched_dep_time</th>\n",
       "      <th>dep_delay</th>\n",
       "      <th>arr_time</th>\n",
       "      <th>sched_arr_time</th>\n",
       "      <th>arr_delay</th>\n",
       "      <th>...</th>\n",
       "      <th>origin</th>\n",
       "      <th>dest</th>\n",
       "      <th>air_time</th>\n",
       "      <th>distance</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>time_hour</th>\n",
       "      <th>plane_year</th>\n",
       "      <th>plane_speed</th>\n",
       "      <th>plane_seats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>517.0</td>\n",
       "      <td>515</td>\n",
       "      <td>2.0</td>\n",
       "      <td>830.0</td>\n",
       "      <td>819</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>EWR</td>\n",
       "      <td>IAH</td>\n",
       "      <td>227.0</td>\n",
       "      <td>1400</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>2013-01-01 05:00:00</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>533.0</td>\n",
       "      <td>529</td>\n",
       "      <td>4.0</td>\n",
       "      <td>850.0</td>\n",
       "      <td>830</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>LGA</td>\n",
       "      <td>IAH</td>\n",
       "      <td>227.0</td>\n",
       "      <td>1416</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>2013-01-01 05:00:00</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>542.0</td>\n",
       "      <td>540</td>\n",
       "      <td>2.0</td>\n",
       "      <td>923.0</td>\n",
       "      <td>850</td>\n",
       "      <td>33.0</td>\n",
       "      <td>...</td>\n",
       "      <td>JFK</td>\n",
       "      <td>MIA</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1089</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>2013-01-01 05:00:00</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>544.0</td>\n",
       "      <td>545</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>1022</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>JFK</td>\n",
       "      <td>BQN</td>\n",
       "      <td>183.0</td>\n",
       "      <td>1576</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>2013-01-01 05:00:00</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>554.0</td>\n",
       "      <td>600</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>812.0</td>\n",
       "      <td>837</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>LGA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>116.0</td>\n",
       "      <td>762</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01 06:00:00</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  year  month  day  dep_time  sched_dep_time  dep_delay  arr_time  \\\n",
       "0      0  2013      1    1     517.0             515        2.0     830.0   \n",
       "1      1  2013      1    1     533.0             529        4.0     850.0   \n",
       "2      2  2013      1    1     542.0             540        2.0     923.0   \n",
       "3      3  2013      1    1     544.0             545       -1.0    1004.0   \n",
       "4      4  2013      1    1     554.0             600       -6.0     812.0   \n",
       "\n",
       "   sched_arr_time  arr_delay  ... origin  dest air_time distance hour  minute  \\\n",
       "0             819       11.0  ...    EWR   IAH    227.0     1400    5      15   \n",
       "1             830       20.0  ...    LGA   IAH    227.0     1416    5      29   \n",
       "2             850       33.0  ...    JFK   MIA    160.0     1089    5      40   \n",
       "3            1022      -18.0  ...    JFK   BQN    183.0     1576    5      45   \n",
       "4             837      -25.0  ...    LGA   ATL    116.0      762    6       0   \n",
       "\n",
       "             time_hour  plane_year  plane_speed plane_seats  \n",
       "0  2013-01-01 05:00:00      1999.0          NaN       149.0  \n",
       "1  2013-01-01 05:00:00      1998.0          NaN       149.0  \n",
       "2  2013-01-01 05:00:00      1990.0          NaN       178.0  \n",
       "3  2013-01-01 05:00:00      2012.0          NaN       200.0  \n",
       "4  2013-01-01 06:00:00      1991.0          NaN       178.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task15_sql=pd.read_sql_query(\"\"\"SELECT\n",
    "                                    flights.*,\n",
    "                                    planes.year AS plane_year,\n",
    "                                    planes.speed AS plane_speed,\n",
    "                                    planes.seats AS plane_seats \n",
    "                                FROM flights LEFT JOIN planes ON flights.tailnum=planes.tailnum\"\"\",\n",
    "                                conn)\n",
    "task15_sql.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PANDAS Equivalent of \"JOINING\" columns from two dataframes**\n",
    "\n",
    "This task is easy to replicate using the pandas.merge() method; a method that was used a little earlier in one of the inefficient solutions to a prior task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed: Outputs are Equal\n"
     ]
    }
   ],
   "source": [
    "planes_renamed = planes[['tailnum', \n",
    "                         'year', \n",
    "                         'speed', \n",
    "                         'seats']].rename(columns={'year': 'plane_year', \n",
    "                                                   'speed': 'plane_speed', \n",
    "                                                   'seats': 'plane_seats'})\n",
    "task15_my = pd.merge(flights, planes_renamed, how='left', on='tailnum').reset_index()\n",
    "\n",
    "try:\n",
    "    pd.testing.assert_frame_equal(task15_sql, task15_my)\n",
    "    print(\"Test passed: Outputs are Equal\")\n",
    "except AssertionError as e:\n",
    "    print(\"Test failed:\", e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the neccesary renaming is performed prior to joining the two Dataframes. The columns that are selected from planes, 'tailnum', 'year', 'speed' and 'seats' are stored as a variable while the rename() method is called to make the neccessary name changes. The 'tailnum' column is selected in this instance because it also exists in the flights DataFrame.\n",
    "\n",
    "Then, pandas.merge() passing the flights DataFrame as the left and the planes DataFrame as the right. 'Left' is passed as an argument to the 'how' parameter which performs the left join, while the 'on' parameter receives the name of the column that is common to both tables.\n",
    "\n",
    "The indices are reset which results in the assertion test passing."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 15 - Performance test**\n",
    "\n",
    "The results of the performance test are below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.85 s ± 92.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "task15_sql=pd.read_sql_query(\"\"\"SELECT\n",
    "                                    flights.*,\n",
    "                                    planes.year AS plane_year,\n",
    "                                    planes.speed AS plane_speed,\n",
    "                                    planes.seats AS plane_seats \n",
    "                                FROM flights LEFT JOIN planes ON flights.tailnum=planes.tailnum\"\"\",\n",
    "                                conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143 ms ± 5.33 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "planes_renamed = planes[['tailnum', \n",
    "                         'year', \n",
    "                         'speed', \n",
    "                         'seats']].rename(columns={'year': 'plane_year', \n",
    "                                                   'speed': 'plane_speed', \n",
    "                                                   'seats': 'plane_seats'})\n",
    "task15_my = pd.merge(flights, planes_renamed, how='left', on='tailnum').reset_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When performing a simple left join, pandas is monumentally faster than SQL. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 16: \"JOINING\" columns from three dataframes with \"INNER JOIN\"\n",
    "\n",
    "The next SQL query increases in complexity by joining three tables instead of two.\n",
    "\n",
    "The query reads data from three tables called \"flights\", \"planes\", and \"airlines\". It selects all columns from the \"planes\" and \"airlines\" tables, and performs an inner join of \"planes\" and \"airlines\" on \"cartail\". The table \"cartail\" represents the unique combinations of carrier and tailnum from the \"flights\" table which is renamed as \"cartail\".\n",
    "\n",
    "An inner join is a type of SQL join that returns only the rows from both tables where there is a match based on the joining column. If there is no match, the row is not included in the result set. So, in other words, if the result of the join is a null value, it is not included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tailnum</th>\n",
       "      <th>year</th>\n",
       "      <th>type</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>model</th>\n",
       "      <th>engines</th>\n",
       "      <th>seats</th>\n",
       "      <th>speed</th>\n",
       "      <th>engine</th>\n",
       "      <th>index</th>\n",
       "      <th>carrier</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>N10156</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>Fixed wing multi engine</td>\n",
       "      <td>EMBRAER</td>\n",
       "      <td>EMB-145XR</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Turbo-fan</td>\n",
       "      <td>5</td>\n",
       "      <td>EV</td>\n",
       "      <td>ExpressJet Airlines Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>N102UW</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>Fixed wing multi engine</td>\n",
       "      <td>AIRBUS INDUSTRIE</td>\n",
       "      <td>A320-214</td>\n",
       "      <td>2</td>\n",
       "      <td>182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Turbo-fan</td>\n",
       "      <td>12</td>\n",
       "      <td>US</td>\n",
       "      <td>US Airways Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>N103US</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>Fixed wing multi engine</td>\n",
       "      <td>AIRBUS INDUSTRIE</td>\n",
       "      <td>A320-214</td>\n",
       "      <td>2</td>\n",
       "      <td>182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Turbo-fan</td>\n",
       "      <td>12</td>\n",
       "      <td>US</td>\n",
       "      <td>US Airways Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>N104UW</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>Fixed wing multi engine</td>\n",
       "      <td>AIRBUS INDUSTRIE</td>\n",
       "      <td>A320-214</td>\n",
       "      <td>2</td>\n",
       "      <td>182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Turbo-fan</td>\n",
       "      <td>12</td>\n",
       "      <td>US</td>\n",
       "      <td>US Airways Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>N10575</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Fixed wing multi engine</td>\n",
       "      <td>EMBRAER</td>\n",
       "      <td>EMB-145LR</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Turbo-fan</td>\n",
       "      <td>5</td>\n",
       "      <td>EV</td>\n",
       "      <td>ExpressJet Airlines Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3334</th>\n",
       "      <td>3317</td>\n",
       "      <td>N997AT</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Fixed wing multi engine</td>\n",
       "      <td>BOEING</td>\n",
       "      <td>717-200</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Turbo-fan</td>\n",
       "      <td>7</td>\n",
       "      <td>FL</td>\n",
       "      <td>AirTran Airways Corporation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3335</th>\n",
       "      <td>3318</td>\n",
       "      <td>N997DL</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>Fixed wing multi engine</td>\n",
       "      <td>MCDONNELL DOUGLAS AIRCRAFT CO</td>\n",
       "      <td>MD-88</td>\n",
       "      <td>2</td>\n",
       "      <td>142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Turbo-fan</td>\n",
       "      <td>4</td>\n",
       "      <td>DL</td>\n",
       "      <td>Delta Air Lines Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3336</th>\n",
       "      <td>3319</td>\n",
       "      <td>N998AT</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Fixed wing multi engine</td>\n",
       "      <td>BOEING</td>\n",
       "      <td>717-200</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Turbo-fan</td>\n",
       "      <td>7</td>\n",
       "      <td>FL</td>\n",
       "      <td>AirTran Airways Corporation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3337</th>\n",
       "      <td>3320</td>\n",
       "      <td>N998DL</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>Fixed wing multi engine</td>\n",
       "      <td>MCDONNELL DOUGLAS CORPORATION</td>\n",
       "      <td>MD-88</td>\n",
       "      <td>2</td>\n",
       "      <td>142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Turbo-jet</td>\n",
       "      <td>4</td>\n",
       "      <td>DL</td>\n",
       "      <td>Delta Air Lines Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3338</th>\n",
       "      <td>3321</td>\n",
       "      <td>N999DN</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>Fixed wing multi engine</td>\n",
       "      <td>MCDONNELL DOUGLAS CORPORATION</td>\n",
       "      <td>MD-88</td>\n",
       "      <td>2</td>\n",
       "      <td>142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Turbo-jet</td>\n",
       "      <td>4</td>\n",
       "      <td>DL</td>\n",
       "      <td>Delta Air Lines Inc.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3339 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index tailnum    year                     type  \\\n",
       "0         0  N10156  2004.0  Fixed wing multi engine   \n",
       "1         1  N102UW  1998.0  Fixed wing multi engine   \n",
       "2         2  N103US  1999.0  Fixed wing multi engine   \n",
       "3         3  N104UW  1999.0  Fixed wing multi engine   \n",
       "4         4  N10575  2002.0  Fixed wing multi engine   \n",
       "...     ...     ...     ...                      ...   \n",
       "3334   3317  N997AT  2002.0  Fixed wing multi engine   \n",
       "3335   3318  N997DL  1992.0  Fixed wing multi engine   \n",
       "3336   3319  N998AT  2002.0  Fixed wing multi engine   \n",
       "3337   3320  N998DL  1992.0  Fixed wing multi engine   \n",
       "3338   3321  N999DN  1992.0  Fixed wing multi engine   \n",
       "\n",
       "                       manufacturer      model  engines  seats  speed  \\\n",
       "0                           EMBRAER  EMB-145XR        2     55    NaN   \n",
       "1                  AIRBUS INDUSTRIE   A320-214        2    182    NaN   \n",
       "2                  AIRBUS INDUSTRIE   A320-214        2    182    NaN   \n",
       "3                  AIRBUS INDUSTRIE   A320-214        2    182    NaN   \n",
       "4                           EMBRAER  EMB-145LR        2     55    NaN   \n",
       "...                             ...        ...      ...    ...    ...   \n",
       "3334                         BOEING    717-200        2    100    NaN   \n",
       "3335  MCDONNELL DOUGLAS AIRCRAFT CO      MD-88        2    142    NaN   \n",
       "3336                         BOEING    717-200        2    100    NaN   \n",
       "3337  MCDONNELL DOUGLAS CORPORATION      MD-88        2    142    NaN   \n",
       "3338  MCDONNELL DOUGLAS CORPORATION      MD-88        2    142    NaN   \n",
       "\n",
       "         engine  index carrier                         name  \n",
       "0     Turbo-fan      5      EV     ExpressJet Airlines Inc.  \n",
       "1     Turbo-fan     12      US              US Airways Inc.  \n",
       "2     Turbo-fan     12      US              US Airways Inc.  \n",
       "3     Turbo-fan     12      US              US Airways Inc.  \n",
       "4     Turbo-fan      5      EV     ExpressJet Airlines Inc.  \n",
       "...         ...    ...     ...                          ...  \n",
       "3334  Turbo-fan      7      FL  AirTran Airways Corporation  \n",
       "3335  Turbo-fan      4      DL         Delta Air Lines Inc.  \n",
       "3336  Turbo-fan      7      FL  AirTran Airways Corporation  \n",
       "3337  Turbo-jet      4      DL         Delta Air Lines Inc.  \n",
       "3338  Turbo-jet      4      DL         Delta Air Lines Inc.  \n",
       "\n",
       "[3339 rows x 13 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task16_sql=pd.read_sql_query(\"\"\"SELECT planes.*, airlines.* FROM\n",
    "                                (SELECT DISTINCT carrier, tailnum FROM flights) AS cartail\n",
    "                                INNER JOIN planes ON cartail.tailnum=planes.tailnum\n",
    "                                INNER JOIN airlines ON cartail.carrier=airlines.carrier\"\"\",\n",
    "                                conn)\n",
    "task16_sql\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PANDAS Equivalent of  \"JOINING\" columns from three dataframes with \"INNER JOIN\"**\n",
    "\n",
    "This query is difficult to replicate in pandas without making an adjustment to the SQL output. I was not able to decipher how SQL performs the joins, or rather which order the joins happen. While I was able to replicate the basic elements of the joins, the SQL output retains the original indices of the rows throughout the joins and it was these specific columns that I could not replicate in order to pass the assertion test.\n",
    "\n",
    "So, I elected to drop the 'index' column from the SQL output and proceed with my solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed: Outputs are Equal\n"
     ]
    }
   ],
   "source": [
    "task16_sql.drop(['index'], axis=1, inplace=True)\n",
    "\n",
    "cartail = flights[['carrier', 'tailnum']].drop_duplicates()\n",
    "task16_my = pd.merge(planes, cartail, how='inner', on='tailnum')\n",
    "task16_my= pd.merge(task16_my, airlines, how='inner', on='carrier')\n",
    "task16_my.sort_values(by=['tailnum', 'carrier'], inplace=True)\n",
    "task16_my.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "try:\n",
    "    pd.testing.assert_frame_equal(task16_sql, task16_my)\n",
    "    print(\"Test passed: Outputs are Equal\")\n",
    "except AssertionError as e:\n",
    "    print(\"Test failed:\", e)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the 'cartail' DataFrame is created by finding the unique combinations using the drop_duplicates() method. Then two pandas.merge() joins are performed to join the DataFrames together while specifying 'inner' as the join type.\n",
    "\n",
    "Finally, the values are sorted by tailnum and carrier and the indices are dropped in order to pass the assertion test. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 16 - Performance test**\n",
    "\n",
    "The results of the performance test are below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240 ms ± 4.09 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "task16_sql=pd.read_sql_query(\"\"\"SELECT planes.*, airlines.* FROM\n",
    "                                (SELECT DISTINCT carrier, tailnum FROM flights) AS cartail\n",
    "                                INNER JOIN planes ON cartail.tailnum=planes.tailnum\n",
    "                                INNER JOIN airlines ON cartail.carrier=airlines.carrier\"\"\",\n",
    "                                conn)\n",
    "task16_sql.drop(['index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.1 ms ± 1.7 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "cartail = flights[['carrier', 'tailnum']].drop_duplicates()\n",
    "task16_my = pd.merge(planes, cartail, how='inner', on='tailnum')\n",
    "task16_my= pd.merge(task16_my, airlines, how='inner', on='carrier')\n",
    "task16_my.sort_values(by=['tailnum', 'carrier'], inplace=True)\n",
    "task16_my.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the previous task, pandas outperforms SQL on this particular task. However, it is important to note that the dispartiy in perfromance is much narrower. It seems that as the joins become more complicated, SQL may begin to outperform pandas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 17: \"JOINING\" \"FILTERED/AVERAGED\" columns with another dataframe \n",
    "\n",
    "In this final task, perhaps the most difficult join of all the tasks is performed by this next SQL query.\n",
    "\n",
    "The query involves joining two tables together, however the join is not performed on the original tables, but instead two subqueries are performed on the \"flights\" and \"weather\" tables and the output of these subqueries are joined together.\n",
    "\n",
    "In the first instance on the \"weather\" table, first the table is filtered by those rows where the origin column is equal to 'EWR'. Then for those rows, the year month and day columns are grouped together and an aggregation mean function is applied to the temperature and humidity columns. The resulting year, month, day, average temp and average humidity columns are selected where average temp andaverage humidity are renamed 'atemp' and 'ahumid' respectively. This subquery is given the name 'weather2' and this will be the left table in the join.\n",
    "\n",
    "Then in the next subquery on the \"flights\" table, all rows where the origin column is equal to 'EWR' are selected. This subquery is given the name 'flights2' which shall be the right table in the join.\n",
    "\n",
    "Once the left join is performed, all columns that were in 'flights2' along with the 'atemp' and 'ahumid' columns from  'weather2' are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dep_time</th>\n",
       "      <th>sched_dep_time</th>\n",
       "      <th>dep_delay</th>\n",
       "      <th>arr_time</th>\n",
       "      <th>sched_arr_time</th>\n",
       "      <th>arr_delay</th>\n",
       "      <th>...</th>\n",
       "      <th>tailnum</th>\n",
       "      <th>origin</th>\n",
       "      <th>dest</th>\n",
       "      <th>air_time</th>\n",
       "      <th>distance</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>time_hour</th>\n",
       "      <th>atemp</th>\n",
       "      <th>ahumid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>517.0</td>\n",
       "      <td>515</td>\n",
       "      <td>2.0</td>\n",
       "      <td>830.0</td>\n",
       "      <td>819</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>N14228</td>\n",
       "      <td>EWR</td>\n",
       "      <td>IAH</td>\n",
       "      <td>227.0</td>\n",
       "      <td>1400</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>2013-01-01 05:00:00</td>\n",
       "      <td>38.4800</td>\n",
       "      <td>58.386087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>554.0</td>\n",
       "      <td>558</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>740.0</td>\n",
       "      <td>728</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>N39463</td>\n",
       "      <td>EWR</td>\n",
       "      <td>ORD</td>\n",
       "      <td>150.0</td>\n",
       "      <td>719</td>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>2013-01-01 05:00:00</td>\n",
       "      <td>38.4800</td>\n",
       "      <td>58.386087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>555.0</td>\n",
       "      <td>600</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>913.0</td>\n",
       "      <td>854</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>N516JB</td>\n",
       "      <td>EWR</td>\n",
       "      <td>FLL</td>\n",
       "      <td>158.0</td>\n",
       "      <td>1065</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01 06:00:00</td>\n",
       "      <td>38.4800</td>\n",
       "      <td>58.386087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>558.0</td>\n",
       "      <td>600</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>923.0</td>\n",
       "      <td>937</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>N53441</td>\n",
       "      <td>EWR</td>\n",
       "      <td>SFO</td>\n",
       "      <td>361.0</td>\n",
       "      <td>2565</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01 06:00:00</td>\n",
       "      <td>38.4800</td>\n",
       "      <td>58.386087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>559.0</td>\n",
       "      <td>600</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>854.0</td>\n",
       "      <td>902</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>N76515</td>\n",
       "      <td>EWR</td>\n",
       "      <td>LAS</td>\n",
       "      <td>337.0</td>\n",
       "      <td>2227</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01 06:00:00</td>\n",
       "      <td>38.4800</td>\n",
       "      <td>58.386087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120830</th>\n",
       "      <td>336752</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>2142.0</td>\n",
       "      <td>2129</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>2239</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>N12957</td>\n",
       "      <td>EWR</td>\n",
       "      <td>PWM</td>\n",
       "      <td>47.0</td>\n",
       "      <td>284</td>\n",
       "      <td>21</td>\n",
       "      <td>29</td>\n",
       "      <td>2013-09-30 21:00:00</td>\n",
       "      <td>62.9075</td>\n",
       "      <td>69.806250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120831</th>\n",
       "      <td>336755</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>2149.0</td>\n",
       "      <td>2156</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>2245.0</td>\n",
       "      <td>2308</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>N813UA</td>\n",
       "      <td>EWR</td>\n",
       "      <td>BOS</td>\n",
       "      <td>37.0</td>\n",
       "      <td>200</td>\n",
       "      <td>21</td>\n",
       "      <td>56</td>\n",
       "      <td>2013-09-30 21:00:00</td>\n",
       "      <td>62.9075</td>\n",
       "      <td>69.806250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120832</th>\n",
       "      <td>336756</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>2150.0</td>\n",
       "      <td>2159</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>2306</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>N10575</td>\n",
       "      <td>EWR</td>\n",
       "      <td>MHT</td>\n",
       "      <td>39.0</td>\n",
       "      <td>209</td>\n",
       "      <td>21</td>\n",
       "      <td>59</td>\n",
       "      <td>2013-09-30 21:00:00</td>\n",
       "      <td>62.9075</td>\n",
       "      <td>69.806250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120833</th>\n",
       "      <td>336760</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>2211.0</td>\n",
       "      <td>2059</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2339.0</td>\n",
       "      <td>2242</td>\n",
       "      <td>57.0</td>\n",
       "      <td>...</td>\n",
       "      <td>N12145</td>\n",
       "      <td>EWR</td>\n",
       "      <td>STL</td>\n",
       "      <td>120.0</td>\n",
       "      <td>872</td>\n",
       "      <td>20</td>\n",
       "      <td>59</td>\n",
       "      <td>2013-09-30 20:00:00</td>\n",
       "      <td>62.9075</td>\n",
       "      <td>69.806250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120834</th>\n",
       "      <td>336762</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>2233.0</td>\n",
       "      <td>2113</td>\n",
       "      <td>80.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>30</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>N578UA</td>\n",
       "      <td>EWR</td>\n",
       "      <td>SFO</td>\n",
       "      <td>318.0</td>\n",
       "      <td>2565</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>2013-09-30 21:00:00</td>\n",
       "      <td>62.9075</td>\n",
       "      <td>69.806250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120835 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index  year  month  day  dep_time  sched_dep_time  dep_delay  \\\n",
       "0            0  2013      1    1     517.0             515        2.0   \n",
       "1            5  2013      1    1     554.0             558       -4.0   \n",
       "2            6  2013      1    1     555.0             600       -5.0   \n",
       "3           13  2013      1    1     558.0             600       -2.0   \n",
       "4           16  2013      1    1     559.0             600       -1.0   \n",
       "...        ...   ...    ...  ...       ...             ...        ...   \n",
       "120830  336752  2013      9   30    2142.0            2129       13.0   \n",
       "120831  336755  2013      9   30    2149.0            2156       -7.0   \n",
       "120832  336756  2013      9   30    2150.0            2159       -9.0   \n",
       "120833  336760  2013      9   30    2211.0            2059       72.0   \n",
       "120834  336762  2013      9   30    2233.0            2113       80.0   \n",
       "\n",
       "        arr_time  sched_arr_time  arr_delay  ... tailnum  origin dest  \\\n",
       "0          830.0             819       11.0  ...  N14228     EWR  IAH   \n",
       "1          740.0             728       12.0  ...  N39463     EWR  ORD   \n",
       "2          913.0             854       19.0  ...  N516JB     EWR  FLL   \n",
       "3          923.0             937      -14.0  ...  N53441     EWR  SFO   \n",
       "4          854.0             902       -8.0  ...  N76515     EWR  LAS   \n",
       "...          ...             ...        ...  ...     ...     ...  ...   \n",
       "120830    2250.0            2239       11.0  ...  N12957     EWR  PWM   \n",
       "120831    2245.0            2308      -23.0  ...  N813UA     EWR  BOS   \n",
       "120832    2250.0            2306      -16.0  ...  N10575     EWR  MHT   \n",
       "120833    2339.0            2242       57.0  ...  N12145     EWR  STL   \n",
       "120834     112.0              30       42.0  ...  N578UA     EWR  SFO   \n",
       "\n",
       "       air_time distance  hour  minute            time_hour    atemp  \\\n",
       "0         227.0     1400     5      15  2013-01-01 05:00:00  38.4800   \n",
       "1         150.0      719     5      58  2013-01-01 05:00:00  38.4800   \n",
       "2         158.0     1065     6       0  2013-01-01 06:00:00  38.4800   \n",
       "3         361.0     2565     6       0  2013-01-01 06:00:00  38.4800   \n",
       "4         337.0     2227     6       0  2013-01-01 06:00:00  38.4800   \n",
       "...         ...      ...   ...     ...                  ...      ...   \n",
       "120830     47.0      284    21      29  2013-09-30 21:00:00  62.9075   \n",
       "120831     37.0      200    21      56  2013-09-30 21:00:00  62.9075   \n",
       "120832     39.0      209    21      59  2013-09-30 21:00:00  62.9075   \n",
       "120833    120.0      872    20      59  2013-09-30 20:00:00  62.9075   \n",
       "120834    318.0     2565    21      13  2013-09-30 21:00:00  62.9075   \n",
       "\n",
       "           ahumid  \n",
       "0       58.386087  \n",
       "1       58.386087  \n",
       "2       58.386087  \n",
       "3       58.386087  \n",
       "4       58.386087  \n",
       "...           ...  \n",
       "120830  69.806250  \n",
       "120831  69.806250  \n",
       "120832  69.806250  \n",
       "120833  69.806250  \n",
       "120834  69.806250  \n",
       "\n",
       "[120835 rows x 22 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task17_sql=pd.read_sql_query(\"\"\"SELECT\n",
    "                                    flights2.*,\n",
    "                                    atemp,\n",
    "                                    ahumid\n",
    "                                FROM ( \n",
    "                                    SELECT * FROM flights WHERE origin='EWR'\n",
    "                                ) AS flights2\n",
    "                                LEFT JOIN ( \n",
    "                                    SELECT \n",
    "                                        year, month, day,\n",
    "                                        AVG(temp) AS atemp,\n",
    "                                        AVG(humid) AS ahumid\n",
    "                                    FROM weather\n",
    "                                    WHERE origin='EWR'\n",
    "                                    GROUP BY year, month, day\n",
    "                                ) AS weather2\n",
    "                                ON flights2.year=weather2.year\n",
    "                                AND flights2.month=weather2.month\n",
    "                                AND flights2.day=weather2.day\"\"\", conn)\n",
    "task17_sql"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PANDAS Equivalent of \"JOINING\" \"FILTERED/AVERAGED\" columns with another dataframe**\n",
    "\n",
    "As before, while I could replicate the general content of this query, I was unable to replicate this query using pandas such that it would pass the assertion test without dropping the indices from the SQL output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed: Outputs are Equal\n"
     ]
    }
   ],
   "source": [
    "task17_sql.drop(['index'], axis=1, inplace=True)\n",
    "\n",
    "flights2 = flights[flights['origin'] == 'EWR']\n",
    "averages = weather[weather['origin']=='EWR'].groupby(['year', 'month', 'day'])[['temp','humid']].mean().reset_index()\n",
    "averages.rename(columns={'temp': 'atemp', 'humid':'ahumid'}, inplace=True)\n",
    "weather2 = weather[weather['origin']=='EWR'].merge(averages, how='left', on=['year', 'month', 'day'])[['year', 'month', 'day', 'atemp', 'ahumid']]\n",
    "\n",
    "task17_my = pd.merge(flights2, weather2, how='left', on=['year', 'month', 'day']).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "try:\n",
    "    pd.testing.assert_frame_equal(task17_sql, task17_my)\n",
    "    print(\"Test passed: Outputs are Equal\")\n",
    "except AssertionError as e:\n",
    "    print(\"Test failed:\", e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to create the flights2 DataFrame by filtering the flights DataFrame based on the condition that 'origin' = 'EWR'.\n",
    "\n",
    "Next, before the weather2 DataFrame could be constructed, the aggregated means of the humidity and temperature columns needed to be computed. This was done by creating a variable called 'averages' which would be used to combine with the weather DataFrame to create the weather2 DataFrame. To compute the averages, the weather DataFrame was first filtered by the condition 'origin' = 'EWR'. Then the groupby() method is applied which groups the DataFrame by year, month and day. Then the temp and humid columns are selected and the mean().method is applied. Resetting the index returns the output into a DataFrame format. The columns are renamed 'atemp' and 'ahumid' to meet the requirements.\n",
    "\n",
    "Then, this averages variable is merged with the weather DataFrame which is also filtered down such that only the rows where the origin column is equal to 'EWR' are selected. This completes the weather2 DataFrame creation step.\n",
    "\n",
    "Then finally, these two DataFrames are merged together using the pandas.merge() method. However, because there were multiple flights that occurred on the same year/month/day, the result is a number of duplicated rows in this output DataFrame. So the drop_duplicates() method is called to eliminate these duplicates. Then the indices are reset to pass the assertion test."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 17 - Performance test**\n",
    "\n",
    "The results of the performance test are below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "919 ms ± 11 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "task17_sql=pd.read_sql_query(\"\"\"SELECT\n",
    "                                    flights2.*,\n",
    "                                    atemp,\n",
    "                                    ahumid\n",
    "                                FROM ( \n",
    "                                    SELECT * FROM flights WHERE origin='EWR'\n",
    "                                ) AS flights2\n",
    "                                LEFT JOIN ( \n",
    "                                    SELECT \n",
    "                                        year, month, day,\n",
    "                                        AVG(temp) AS atemp,\n",
    "                                        AVG(humid) AS ahumid\n",
    "                                    FROM weather\n",
    "                                    WHERE origin='EWR'\n",
    "                                    GROUP BY year, month, day\n",
    "                                ) AS weather2\n",
    "                                ON flights2.year=weather2.year\n",
    "                                AND flights2.month=weather2.month\n",
    "                                AND flights2.day=weather2.day\"\"\", conn)\n",
    "\n",
    "task17_sql.drop(['index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.06 s ± 50.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "flights2 = flights[flights['origin'] == 'EWR']\n",
    "averages = weather[weather['origin']=='EWR'].groupby(['year', 'month', 'day'])[['temp','humid']].mean().reset_index()\n",
    "averages.rename(columns={'temp': 'atemp', 'humid':'ahumid'}, inplace=True)\n",
    "weather2 = weather[weather['origin']=='EWR'].merge(averages, how='left', on=['year', 'month', 'day'])[['year', 'month', 'day', 'atemp', 'ahumid']]\n",
    "\n",
    "task17_my = pd.merge(flights2, weather2, how='left', on=['year', 'month', 'day']).drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show that SQL now outperforms pandas by a decent margin when performing this type of join. As with the results in previous tests, when pandas is required to perform filtering then the performance starts to decrease."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In summary, This exercise began with a naive theory and hypothesis regarding pandas and SQL which was partially supported. The results demonstrate that the exact same outputs can be acheived using SQL queries or pandas methods and that depending on the task at hand one approach may outperform the other. For instance, while pandas may be faster on the whole, it seems that as the outputs become more complicated with more filtering, then SQL may be better. The implications of these findings boil down to choosing the right data infrastructures for the tasks to be performed. There are advantages to using SQL to store data in databases as opposed to maintaining data in csv spreadsheets that may outweigh the potential peformance advatanges that pandas may have over SQL in terms of returning the output. This exercise was a novice approach to creating a taxonomy of output types and determing whether pandas or SQL performed better. A future study may wish to create a more robust taxonomy of the task types with clear definitions for the outputs. Then proper hypothesis tests for performance can be generated for each task type and the results be reported."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SIT731",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4a721878d74a30a26e5fc6b049397f54d21255a21ba2acbd84c38afc45a44b24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
